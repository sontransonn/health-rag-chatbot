import os, json, glob
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.schema import Document

# L·∫•y file ƒë·∫ßu ti√™n ƒë·ªÉ test
file_path = glob.glob("data/preprocessed/*.json")[0]

with open(file_path, "r", encoding="utf-8") as f:
    data = json.load(f)

# T·∫°o Document
docs = [
    Document(
        page_content=item.get("content", ""),
        metadata=item.get("metadata", {})
    )
    for item in data
]

print(f"‚úÖ S·ªë l∆∞·ª£ng documents: {len(docs)}")

# T·∫°o embeddings
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# T·∫°o vectorstore
vectorstore = FAISS.from_documents(docs, embeddings)

# Th·ª≠ truy v·∫•n
query = "b·ªánh b√©o ph√¨ l√† g√¨"
docs_with_scores = vectorstore.similarity_search_with_score(query, k=20)

for doc, score in docs_with_scores:
    print("\nüîç K·∫øt qu·∫£ t√¨m ki·∫øm:")
    print(f"Score: {score:.4f}")
    print(f"N·ªôi dung: {doc.page_content[:200]}...")
    print(f"Metadata: {doc.metadata}")
